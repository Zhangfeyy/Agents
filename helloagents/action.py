import re
import os
from tavily import TavilyClient
from openai import OpenAI
from openai.types.chat import ChatCompletionMessageParam
import requests


AGENT_SYSTEM_PROMPT = """
你是一个智能旅行助手，任务是分析用户请求，并使用可用工具一步步解决问题。

# 可用工具：
- 'get_weather(city: str)': 查询指定城市的实时天气。
- 'get_attraction(city: str, weather: str)': 根据天气推荐景点

# 输出格式要求：
你的每次回复必须严格遵循以下格式，包含一对Thought和Action：

Thought：你的思考过程和下一步计划
Action：你要执行的具体行动

Action的格式必须是以下之一：

1. 调用工具：function_name(arg_name="arg_value")
2. 结束任务：Finish[最终答案]

# 重要提示：
- 每次只输出一对Thought-Action
- Action必须在同一行，不要换行
- 当收集到足够信息可以回答用户问题时，必须使用 Action: Finish[最终答案]格式结束

请开始吧！
"""


def get_weather(city: str) -> str:
    """
    通过调用wttr.in API 查询天气信息

    """

    """
    {
  "current_condition": [
    {
      "temp_C": "2",
      "weatherDesc": [{"value": "Partly cloudy"}],
      "humidity": "81",
      ...
    }
  ],
  "weather": [...],
  ...
}
    """

    # API 端点，我们请求JSON格式的数据
    url = f"https://wttr.in/{city}?format=j1"

    try:
        # 发起网络请求
        response = requests.get(url)
        # 检查相应状态码是否为200 （成功）
        response.raise_for_status()  # otherwise it will be thrown to exception
        # 解析返回的JSON数据
        data = response.json()

        # 提取当前天气状况
        current_condition = data['current_condition'][0]
        weather_desc = current_condition['weatherDesc'][0]['value']
        temp_c = current_condition['temp_C']

        # 格式化成自然语言返回
        return f"{city}当前天气：{weather_desc}, 气温{temp_c}摄氏度"

    except requests.exceptions.RequestException as e:
        # 处理网络错误
        return f"错误：查询天气时遇到网络问题 - {e}"
    except (KeyError, IndexError) as e:
        # 处理数据解析错误
        return f"错误： 解析天气数据失败，可能时城市名无效 - {e}"


def get_attraction(city: str, weather: str) -> str:
    """
    根据城市和天气，使用Tavily Search API 搜索并返回优化后的景点推荐。
    """

    # 1. 从环境变量中读取API密钥，需要在文件里显性设置（作用域仅限当前文件）或者在系统里设置
    api_key = os.environ.get("TAVILY_API_KEY")

    # 2. 初始化Tavily客户端
    tavily = TavilyClient(api_key=api_key)

    # 3. 构造一个精确的查询
    query = f"'{city}在{weather}'天气下最值得去的旅游景点推荐及理由"

    try:
        # 4. 调用API，include_answer=True会返回一个综合性的回答
        response = tavily.search(
            query=query, search_depth="basic", include_answer=True)

        # 5. Tavily返回的结果已经非常干净，可以直接使用
        # response['answer'] 是一个基于所有搜索结果的总结性回答
        if response.get("answer"):
            return response["answer"]

        # 没有综合性回答，则格式化原始结果
        formatted_results = []
        for result in response.get("results", []):
            formatted_results.append(
                f"- {result['title']}: {result['content']}")

        if not formatted_results:
            return "抱歉，没有找到相关的旅游景点推荐"

        return "根据搜索，为您找到以下信息：\n"+"\n.join(formatted_results)"
    except Exception as e:
        return f"错误：执行Tavily时出现问题 -{e}"


available_tools = {
    "get_weather": get_weather,
    "get_attraction": get_attraction
}


class OpenAICompatibleClient:
    """
        一个调用任何兼容OpenAI接口的LLM服务的客户端
        """

    def __init__(self, model: str, api_key: str, base_url: str):
        self.model = model
        self.client = OpenAI(api_key=api_key, base_url=base_url)

    # 生成回复的方法
    def generate(self, prompt: str, system_prompt: str) -> str:
        """
        调用LLM API生成回应
        """
        print("正在调用大语言模型...")
        try:
            messages: list[ChatCompletionMessageParam] = [
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': prompt}
            ]
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
            )

            answer = str(response.choices[0].message.content)
            print("大预言模型响应成功。")
            return answer

        except Exception as e:
            print(f"调用LLM API时发生错误 -{e}")
            return "错误：调用语言模型服务出错"


# 配置LLM客户端
API_KEY = "sk-kXZCte9skfk5mekW0dAe190907Da4a52884242EdBa56185e"
BASE_URL = "https://aihubmix.com/v1"
MODEL_ID = "coding-glm-4.6-free"
TAVILY_API_KEY = "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"
os.environ['TAVILY_API_KEY'] = "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"

llm = OpenAICompatibleClient(
    model=MODEL_ID,
    api_key=API_KEY,
    base_url=BASE_URL
)

# 初始化
user_prompt = "你好，帮我查询一下今天北京的天气，根据天气推荐一个合适的旅游景点。"
prompt_history = [f"用户请求： {user_prompt}"]

print(f"用户输入： {user_prompt}\n" + "="*40)

# 运行主循环，一轮循环Thought, Action, Observation 全部存储进user_prompt
for i in range(5):
    print(f"--循环{i+1}--\n")

    # 3.1 构建prompt
    full_prompt = "\n".join(prompt_history)

    # 3.2 调用LLM思考
    llm_output = llm.generate(full_prompt, system_prompt=AGENT_SYSTEM_PROMPT)
    # 模型可能会输出多余的Thought-Action，需要截断
    match = re.search(
        r'(Thought:.*?Action:.*?)(?=\n\s*(?:Thought:|Action:|Observation:)|\Z)', llm_output, re.DOTALL)
    if match:
        truncated = match.group(1).strip() #提取并去除首尾空格
        if truncated != llm_output.strip():
            llm_output = truncated
            print("已截断")
    print(f"模型输出：\n{llm_output}\n")
    
    prompt_history.append(llm_output)

    # 3.3 解析并执行行动
    # 千万注意这里和system prompt里的标点符号一致！！！
    action_match = re.search(r"Action：(.*)", llm_output, re.DOTALL)
    if not action_match:
        observation = "错误，未解析到Action字段。请确保你的回复严格遵循 'Thought:...Action:...'的格式。"
        observation_str = f"Observation: {observation}"
        print(f"{observation_str}\n" + "="*40)
        prompt_history.append(observation_str)
        continue # 进入下一次循环

    action_str = action_match.group(1).strip()

    if action_str.startswith("Finish"):
        final_match = re.match(r"Finish\[(.*)\]", action_str)
        if final_match:
            final_answer = final_match.group(1)
            print(f"任务完成，最终答案: {final_answer}")
            break
    tool_match = re.match(r"(\w+)\(", action_str)
    tool_name = tool_match.group(1) if tool_match else ""
    args_match = re.search(r"\((.*)\)", action_str)
    args_str = args_match.group(1) if args_match else ""
    kwargs = dict(re.findall(r'(\w+)="([^"]*)"', args_str))

    if tool_name in available_tools:
        observation = available_tools[tool_name](**kwargs)
    else:
        observation = f"错误：未定义的工具'{tool_name}'"

    # 3.4 记录观察结果
    observation_str = f"Observation: {observation}"
    print(f"{observation_str}\n" + "="*40)
    prompt_history.append(observation_str)
